{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPt5q27L5557"
   },
   "source": [
    "# Spark Map & Reduce (CS246)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0-YhEpP_Ds-"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zsj5WYpR9QId"
   },
   "source": [
    "Let's setup Spark on your Colab environment.  Run the cell below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CJ71AKe91eh"
   },
   "source": [
    "Now we authenticate a Google Drive client to download the file we will be processing in our Spark job.\n",
    "\n",
    "**Make sure to follow the interactive instructions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwtlO4_m_LbQ"
   },
   "source": [
    "If you executed the cells above, you should be able to see the file *pg100.txt* under the \"Files\" tab on the left panel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRaF2A_j_nC7"
   },
   "source": [
    "### Your task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebLNUxP0_8x3"
   },
   "source": [
    "If you run successfully the setup stage, you are ready to work on the *pg100.txt* file which contains a copy of the complete works of Shakespeare.\n",
    "\n",
    "Write a Spark application which outputs the number of words that start with each letter. This means that for every letter we want to count the total number of (non-unique) words that start with a specific letter. In your implementation **ignore the letter case**, i.e., consider all words as lower case. Also, you can ignore all the words **starting** with a non-alphabetic character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xu-e7Ph2_ruG"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jaeyongs-mbp:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd301fdd400>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# create the Spark Session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# create the Spark Context\n",
    "sc = spark.sparkContext\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AuAxGFPFB43Y"
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "reader = sc.textFile(\"./dataset/pg100.txt\")\n",
    "count = reader.flatMap(lambda x: x.split()).map(lambda x: x.lower()).map(lambda x: (x[0], 1)).reduceByKey(add).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7jDCs412ZZcF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('p', 27759),\n",
       " ('g', 20782),\n",
       " ('c', 34567),\n",
       " ('s', 65705),\n",
       " ('b', 45455),\n",
       " ('i', 62167),\n",
       " ('r', 14265),\n",
       " ('y', 25855),\n",
       " ('l', 29569),\n",
       " ('*', 24),\n",
       " ('d', 29713),\n",
       " ('1', 458),\n",
       " ('[', 2073),\n",
       " ('#', 3),\n",
       " ('j', 3339),\n",
       " ('h', 60563),\n",
       " ('.', 52),\n",
       " ('\"', 356),\n",
       " ('9', 28),\n",
       " ('4', 46),\n",
       " ('_', 1),\n",
       " ('8', 15),\n",
       " ('?', 2),\n",
       " ('}', 2),\n",
       " ('$', 1),\n",
       " ('0', 6),\n",
       " ('t', 123602),\n",
       " ('e', 18697),\n",
       " ('o', 43494),\n",
       " ('w', 59597),\n",
       " ('f', 36814),\n",
       " ('u', 9170),\n",
       " ('a', 84836),\n",
       " ('n', 26759),\n",
       " ('m', 55676),\n",
       " ('2', 95),\n",
       " ('<', 248),\n",
       " ('v', 5728),\n",
       " ('(', 639),\n",
       " ('k', 9418),\n",
       " ('3', 59),\n",
       " ('/', 2),\n",
       " (\"'\", 3804),\n",
       " ('5', 35),\n",
       " ('q', 2377),\n",
       " ('6', 22),\n",
       " ('7', 17),\n",
       " ('z', 71),\n",
       " ('-', 52),\n",
       " (']', 7),\n",
       " ('x', 14),\n",
       " ('&', 21),\n",
       " (':', 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIrXJyVNP2AI"
   },
   "source": [
    "Once you obtained the desired results, **head over to Gradescope and submit your solution for this Colab**!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS246 - Colab 1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
